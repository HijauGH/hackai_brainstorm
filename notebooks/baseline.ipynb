{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost osmnx scipy geopy protobuf==3.20.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TC8rq3rz8Cw4",
        "outputId": "33e67e18-c6b5-49af-e06a-a1bc48064ea5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.5)\n",
            "Requirement already satisfied: osmnx in /usr/local/lib/python3.10/dist-packages (1.9.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (3.20.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: geopandas>=0.12 in /usr/local/lib/python3.10/dist-packages (from osmnx) (0.13.2)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.10/dist-packages (from osmnx) (3.3)\n",
            "Requirement already satisfied: requests>=2.27 in /usr/local/lib/python3.10/dist-packages (from osmnx) (2.31.0)\n",
            "Requirement already satisfied: shapely>=2.0 in /usr/local/lib/python3.10/dist-packages (from osmnx) (2.0.4)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.10/dist-packages (from geopy) (2.0)\n",
            "Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.12->osmnx) (1.9.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.12->osmnx) (24.1)\n",
            "Requirement already satisfied: pyproj>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.12->osmnx) (3.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27->osmnx) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27->osmnx) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27->osmnx) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27->osmnx) (2024.6.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.4.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.12->osmnx) (23.2.0)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.12->osmnx) (8.1.7)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.12->osmnx) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.12->osmnx) (0.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2n-4-J6ffRWk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from scipy.spatial import cKDTree\n",
        "from geopy.distance import geodesic\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "import osmnx as ox\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point, MultiPoint\n",
        "import requests\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', message=\"The indices of the two GeoSeries are different.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def haversine_distance(lat1, lon1, lat2, lon2):\n",
        "    R = 6371  # радиус Земли в километрах\n",
        "\n",
        "    lat1_rad = np.radians(lat1)\n",
        "    lon1_rad = np.radians(lon1)\n",
        "    lat2_rad = np.radians(lat2)\n",
        "    lon2_rad = np.radians(lon2)\n",
        "\n",
        "    dlat = lat2_rad - lat1_rad\n",
        "    dlon = lon2_rad - lon1_rad\n",
        "\n",
        "    a = np.sin(dlat/2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon/2)**2\n",
        "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
        "\n",
        "    distance = R * c\n",
        "    return distance"
      ],
      "metadata": {
        "id": "dqVY5K--6aMZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_json('train_data.json')\n",
        "df=pd.concat([df,pd.json_normalize(df['targetAudience'])], axis=1)\n",
        "df=df.drop(['targetAudience','id'], axis=1)"
      ],
      "metadata": {
        "id": "yZvNqOcHhTjc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['geometry'] = df['points'].apply(lambda x: Point(float(x[0]['lon']), float(x[0]['lat'])))\n",
        "gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
        "gdf.crs = 'EPSG:4326'"
      ],
      "metadata": {
        "id": "-P0s_Nk7lgKH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "moscow = ox.geocode_to_gdf('Moscow, Russia')"
      ],
      "metadata": {
        "id": "ypQ-tdR_l6xW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Расстояние до центра (Красная площадь)\n",
        "red_square = Point(37.620393, 55.753930)\n",
        "gdf['distance_to_center'] = gdf.apply(lambda row: haversine_distance(row.geometry.y, row.geometry.x, red_square.y, red_square.x), axis=1)\n",
        "\n",
        "# Ближайшая станция метро\n",
        "metro_stations = ox.features_from_place('Moscow, Russia', tags={'railway': 'station', 'station': 'subway'})\n",
        "gdf['distance_to_metro'] = gdf.apply(lambda row: metro_stations.distance(row.geometry).min() / 1000, axis=1)\n"
      ],
      "metadata": {
        "id": "AuulTJL96n3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c101ee-efdf-4d1c-cc7d-ac1a47ea9a3e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-85064ada1a9d>:7: UserWarning: Geometry is in a geographic CRS. Results from 'distance' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  gdf['distance_to_metro'] = gdf.apply(lambda row: metro_stations.distance(row.geometry).min() / 1000, axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Плотность населения (примерные данные)\n",
        "# population_density = {\n",
        "#     'Центральный': 5000,\n",
        "#     'Северный': 3000,\n",
        "#     'Северо-Восточный': 3500,\n",
        "#     'Восточный': 4000,\n",
        "#     'Юго-Восточный': 3800,\n",
        "#     'Южный': 4200,\n",
        "#     'Юго-Западный': 3700,\n",
        "#     'Западный': 3900,\n",
        "#     'Северо-Западный': 3600,\n",
        "#     'Зеленоградский': 3200,\n",
        "#     'Новомосковский': 2500,\n",
        "#     'Троицкий': 2000\n",
        "# }\n",
        "\n",
        "population_density = {\n",
        "    'Центральный': 11702.67,\n",
        "    'Северный': 10709.15,\n",
        "    'Северо-Восточный': 14289.05\t,\n",
        "    'Восточный': 9743.75,\n",
        "    'Юго-Восточный': 12893.76,\n",
        "    'Южный': 13422.73,\n",
        "    'Юго-Западный': 12890.82,\n",
        "    'Западный': 9312.38,\n",
        "    'Северо-Западный': 11144.78,\n",
        "    'Зеленоградский': 7272.25,\n",
        "    'Новомосковский': 1497.79,\n",
        "    'Троицкий': 181.13\n",
        "}\n",
        "\n",
        "# Функция для определения административного округа\n",
        "def get_district(point):\n",
        "    for idx, row in moscow.iterrows():\n",
        "        if row.geometry.contains(point):\n",
        "            return row['name']\n",
        "    return 'Unknown'\n",
        "\n",
        "gdf['district'] = gdf.apply(lambda row: get_district(row.geometry), axis=1)\n",
        "gdf['population_density'] = gdf['district'].map(population_density)\n"
      ],
      "metadata": {
        "id": "lCcfeRia7amm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffb04ea9-1d26-47c0-ba14-7b22d9a37838"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shopping_centers = ox.features_from_place('Moscow, Russia', tags={'shop': 'mall'})\n",
        "gdf['distance_to_shopping_center'] = gdf.apply(lambda row: shopping_centers.distance(row.geometry).min() / 1000, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQIClyEf7qTq",
        "outputId": "00f576e1-ded7-40af-c33f-5ab6b51bd748"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "<ipython-input-9-003a9c48d68e>:2: UserWarning: Geometry is in a geographic CRS. Results from 'distance' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  gdf['distance_to_shopping_center'] = gdf.apply(lambda row: shopping_centers.distance(row.geometry).min() / 1000, axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_on_intervals(min_val, max_val, n):\n",
        "    step = (max_val - min_val) / n\n",
        "    intervals = [min_val + (step * x) for x in range(n + 1)]\n",
        "    return intervals"
      ],
      "metadata": {
        "id": "NOA5g6_UXlol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45347e16-da58-4145-9bf3-20b3bf1675ca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_groups(x_intervals, y_intervals):\n",
        "    groups = {}\n",
        "    x_intervals = np.concatenate([[-np.inf], x_intervals, [np.inf]])\n",
        "    y_intervals = np.concatenate([[-np.inf], y_intervals, [np.inf]])\n",
        "\n",
        "    for x_i in range(len(x_intervals) - 1):\n",
        "        for y_i in range(len(y_intervals) - 1):\n",
        "            groups[f'x:{x_intervals[x_i]:.2f}-{x_intervals[x_i+1]:.2f}|y:{y_intervals[y_i]:.2f}-{y_intervals[y_i+1]:.2f}'] = 0\n",
        "\n",
        "    return groups"
      ],
      "metadata": {
        "id": "znF3Kiqin9GN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_on_groups(x_vals, y_vals, x_intervals, y_intervals, groups, only_vals=False):\n",
        "    for x, y in zip(x_vals, y_vals):\n",
        "        for x_i in range(len(x_intervals) - 1):\n",
        "            for y_i in range(len(y_intervals) - 1):\n",
        "                if (x_intervals[x_i] <= x < x_intervals[x_i + 1]) and (y_intervals[y_i] <= y < y_intervals[y_i + 1]):\n",
        "                    groups[f'x:{x_intervals[x_i]:.2f}-{x_intervals[x_i+1]:.2f}|y:{y_intervals[y_i]:.2f}-{y_intervals[y_i+1]:.2f}'] += 1\n",
        "\n",
        "    return list(groups.values()) if only_vals else groups"
      ],
      "metadata": {
        "id": "UC9INo92aFIu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(config, gdf):\n",
        "    x_intervals = split_on_intervals(config['min_xval'], config['max_xval'], config['x_ngroups'])\n",
        "    y_intervals = split_on_intervals(config['min_yval'], config['max_yval'], config['y_ngroups'])\n",
        "\n",
        "    groups = create_groups(x_intervals, y_intervals)\n",
        "\n",
        "    groups_values = []\n",
        "    for _, row in gdf.iterrows():\n",
        "        points = np.array([[float(x['lat']), float(x['lon'])] for x in row['points']])\n",
        "        group_values = sort_on_groups(points[:, 0], points[:, 1], x_intervals, y_intervals, groups.copy(), only_vals=True)\n",
        "        groups_values.append(group_values)\n",
        "\n",
        "    groups_values = np.array(groups_values)\n",
        "\n",
        "    result = pd.DataFrame(groups_values, columns=list(groups.keys()))\n",
        "\n",
        "    # Add additional features\n",
        "    result['num_points'] = gdf['points'].apply(len)\n",
        "    result['avg_lat'] = gdf['points'].apply(lambda x: np.mean([float(p['lat']) for p in x]))\n",
        "    result['avg_lon'] = gdf['points'].apply(lambda x: np.mean([float(p['lon']) for p in x]))\n",
        "    result['avg_azimuth'] = gdf['points'].apply(lambda x: np.mean([p['azimuth'] for p in x]))\n",
        "\n",
        "    # # Add target audience features\n",
        "    result['gender'] = gdf['gender'].map({'all': 0, 'male': 1, 'female': 2})\n",
        "    result['ageFrom'] = gdf['ageFrom']\n",
        "    result['ageTo'] = gdf['ageTo']\n",
        "    result['age_range'] = gdf['ageTo'] - gdf['ageFrom']\n",
        "    result['income'] = gdf['income'].map({'a': 1, 'b': 2, 'c': 3, 'ab': 4, 'bc': 5, 'ac': 6, 'abc': 7})\n",
        "\n",
        "    #Add new features\n",
        "    result['distance_to_center'] = gdf['distance_to_center']\n",
        "    result['distance_to_metro'] = gdf['distance_to_metro']\n",
        "    result['population_density'] = gdf['population_density']\n",
        "    result['distance_to_shopping_center'] = gdf['distance_to_shopping_center']\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "5-4KAqVgiNZN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {'min_xval':55.55, 'max_xval':55.95, 'min_yval':37.3, 'max_yval':37.9, 'x_ngroups': 33, 'y_ngroups': 33}"
      ],
      "metadata": {
        "id": "WBJRjN7ri_iq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = create_dataset(config, gdf)\n",
        "y = df['value']"
      ],
      "metadata": {
        "id": "wqaooAHfih5c"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "G10riNk4pXAx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af67da55-5ba0-4f58-b7fa-d9b3bde2683b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CatBoostRegressor(iterations=1700,\n",
        "                          depth=6,\n",
        "                          learning_rate=0.04,\n",
        "                          grow_policy='SymmetricTree',\n",
        "                          random_state=42,\n",
        "                          loss_function='RMSE')\n",
        "\n",
        "model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=100)"
      ],
      "metadata": {
        "id": "dDpAZNp-629T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbb2c8ca-53f2-4d6e-cff1-b8c6126b982e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 23.7090362\ttest: 21.7998817\tbest: 21.7998817 (0)\ttotal: 59.8ms\tremaining: 1m 41s\n",
            "100:\tlearn: 9.3372228\ttest: 9.4378079\tbest: 9.4378079 (100)\ttotal: 1.16s\tremaining: 18.4s\n",
            "200:\tlearn: 7.4722266\ttest: 8.1722549\tbest: 8.1722549 (200)\ttotal: 2.23s\tremaining: 16.7s\n",
            "300:\tlearn: 6.3170122\ttest: 7.5529970\tbest: 7.5529970 (300)\ttotal: 3.32s\tremaining: 15.4s\n",
            "400:\tlearn: 5.6856184\ttest: 7.2358616\tbest: 7.2358616 (400)\ttotal: 4.38s\tremaining: 14.2s\n",
            "500:\tlearn: 5.1721973\ttest: 7.0084156\tbest: 7.0084156 (500)\ttotal: 5.44s\tremaining: 13s\n",
            "600:\tlearn: 4.8209616\ttest: 6.8417990\tbest: 6.8413028 (599)\ttotal: 6.51s\tremaining: 11.9s\n",
            "700:\tlearn: 4.5891715\ttest: 6.7861759\tbest: 6.7837217 (693)\ttotal: 7.7s\tremaining: 11s\n",
            "800:\tlearn: 4.3496359\ttest: 6.7172801\tbest: 6.7172801 (800)\ttotal: 9.64s\tremaining: 10.8s\n",
            "900:\tlearn: 4.1572546\ttest: 6.6714219\tbest: 6.6709926 (899)\ttotal: 11.8s\tremaining: 10.5s\n",
            "1000:\tlearn: 4.0062527\ttest: 6.6429842\tbest: 6.6411867 (994)\ttotal: 14.1s\tremaining: 9.83s\n",
            "1100:\tlearn: 3.8706099\ttest: 6.6241268\tbest: 6.6240385 (1098)\ttotal: 16.4s\tremaining: 8.92s\n",
            "1200:\tlearn: 3.7719796\ttest: 6.6218424\tbest: 6.6139668 (1174)\ttotal: 17.8s\tremaining: 7.4s\n",
            "1300:\tlearn: 3.6755854\ttest: 6.6147187\tbest: 6.6115836 (1265)\ttotal: 18.9s\tremaining: 5.79s\n",
            "1400:\tlearn: 3.5793222\ttest: 6.6026851\tbest: 6.5984863 (1385)\ttotal: 20s\tremaining: 4.26s\n",
            "1500:\tlearn: 3.4991780\ttest: 6.5950285\tbest: 6.5950039 (1498)\ttotal: 21.1s\tremaining: 2.79s\n",
            "1600:\tlearn: 3.4440036\ttest: 6.5978333\tbest: 6.5931909 (1521)\ttotal: 22.1s\tremaining: 1.37s\n",
            "1699:\tlearn: 3.3958116\ttest: 6.6034777\tbest: 6.5931909 (1521)\ttotal: 23.2s\tremaining: 0us\n",
            "\n",
            "bestTest = 6.593190932\n",
            "bestIteration = 1521\n",
            "\n",
            "Shrink model to first 1522 iterations.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostRegressor at 0x7e50345b0880>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "BCeMCmLz-R-h"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "custom = max(1 - rmse/30, 0) ** 4\n",
        "\n",
        "print(f'RMSE: {rmse:.4f}')\n",
        "print(f'R²: {r2:.4f}')\n",
        "print(f'MAE: {mae:.4f}')\n",
        "print(f'Custom: {custom:.4f}')\n",
        "\n",
        "feature_importance = pd.DataFrame({'feature': X.columns, 'importance': model.feature_importances_})\n",
        "print(feature_importance.sort_values('importance', ascending=False))\n"
      ],
      "metadata": {
        "id": "KqwJN8T6Kmyk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a692d0d-821d-4149-ec00-c5873ec42f96"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 6.5932\n",
            "R²: 0.9112\n",
            "MAE: 4.2135\n",
            "Custom: 0.3706\n",
            "                          feature  importance\n",
            "1225                   num_points   19.050110\n",
            "128   x:55.57-55.59|y:37.70-37.72    3.239270\n",
            "824   x:55.82-55.83|y:37.63-37.65    3.060080\n",
            "1026  x:55.89-55.90|y:37.48-37.50    2.870601\n",
            "536   x:55.72-55.73|y:37.48-37.50    2.737688\n",
            "...                           ...         ...\n",
            "456   x:55.70-55.71|y:37.30-37.32    0.000000\n",
            "457   x:55.70-55.71|y:37.32-37.34    0.000000\n",
            "459   x:55.70-55.71|y:37.35-37.37    0.000000\n",
            "460   x:55.70-55.71|y:37.37-37.39    0.000000\n",
            "619   x:55.74-55.76|y:37.72-37.74    0.000000\n",
            "\n",
            "[1238 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Тестирование"
      ],
      "metadata": {
        "id": "r_wP2WVaOktf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_predictions(y_test,y_pred):\n",
        "  for yt, yp in zip(y_test,y_pred):\n",
        "    print(f'{yt} | {yp}')"
      ],
      "metadata": {
        "id": "U0mtyiQlR7Se",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9731144b-636e-45c7-e89d-0d800a983f3d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "slice_idx=10"
      ],
      "metadata": {
        "id": "L1Q_iqZRS4ji"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.round(y_pred, 2)\n",
        "show_predictions(y_test[:slice_idx],y_pred[:slice_idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwGFdrXMSdnY",
        "outputId": "e3751f93-2871-45a3-9541-67d10926f54e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11 | 1.48\n",
            "33.41 | 17.46\n",
            "0.0 | -0.61\n",
            "0.17 | 1.14\n",
            "53.04 | 56.63\n",
            "14.13 | 13.2\n",
            "2.71 | 2.25\n",
            "17.21 | 13.6\n",
            "34.89 | 38.02\n",
            "19.85 | 29.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from functools import partial\n",
        "\n",
        "def get_point_coordinates(gdf):\n",
        "    points = []\n",
        "    for geom in gdf.geometry:\n",
        "        if isinstance(geom, Point):\n",
        "            points.append((geom.x, geom.y))\n",
        "        elif isinstance(geom, MultiPoint):\n",
        "            # Для MultiPoint берем первую точку\n",
        "            points.append((geom.geoms[0].x, geom.geoms[0].y))\n",
        "    return np.array(points)\n",
        "\n",
        "# Load and prepare data\n",
        "metro_stations = ox.features_from_place('Moscow, Russia', tags={'railway': 'station', 'station': 'subway'})\n",
        "shopping_centers = ox.features_from_place('Moscow, Russia', tags={'shop': 'mall'})\n",
        "moscow = ox.geocode_to_gdf('Moscow, Russia')\n",
        "\n",
        "# Function to get centroid coordinates\n",
        "def get_centroid_coords(geom):\n",
        "    if geom.geom_type == 'Point':\n",
        "        return (geom.y, geom.x)\n",
        "    else:\n",
        "        centroid = geom.centroid\n",
        "        return (centroid.y, centroid.x)\n",
        "\n",
        "# Prepare KD-trees\n",
        "metro_points = np.array([get_centroid_coords(geom) for geom in metro_stations.geometry])\n",
        "shopping_points = np.array([get_centroid_coords(geom) for geom in shopping_centers.geometry])\n",
        "metro_tree = cKDTree(metro_points)\n",
        "shopping_tree = cKDTree(shopping_points)\n",
        "\n",
        "# Prepare spatial index\n",
        "moscow_sindex = moscow.sindex\n",
        "\n",
        "\n",
        "def enrich_data_vectorized(points, target_audience):\n",
        "    df = pd.DataFrame(points)\n",
        "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.lon, df.lat))\n",
        "    gdf.crs = 'EPSG:4326'\n",
        "\n",
        "    red_square = (55.753930, 37.620393)\n",
        "\n",
        "    # Vectorized distance calculation\n",
        "    coords = np.column_stack((gdf.geometry.y, gdf.geometry.x))\n",
        "    gdf['distance_to_center'] = geodesic(red_square, coords).kilometers\n",
        "\n",
        "    # Use KD-tree for faster nearest neighbor search\n",
        "    gdf['distance_to_metro'] = metro_tree.query(coords)[0]\n",
        "    gdf['distance_to_shopping_center'] = shopping_tree.query(coords)[0]\n",
        "\n",
        "    # Vectorized district assignment\n",
        "    possible_matches_index = list(moscow_sindex.intersection(gdf.total_bounds))\n",
        "    possible_matches = moscow.iloc[possible_matches_index]\n",
        "    points_in_districts = gpd.sjoin(gdf, possible_matches, how='left', predicate='within')\n",
        "    gdf['district'] = points_in_districts['name']\n",
        "\n",
        "    gdf['population_density'] = gdf['district'].map(population_density)\n",
        "\n",
        "    # Add target audience data\n",
        "    for key, value in target_audience.items():\n",
        "        gdf[key] = value\n",
        "\n",
        "    return create_dataset(config, gdf)\n",
        "\n",
        "def predict_reach_batch(points_batch, target_audience):\n",
        "    X = enrich_data_vectorized(points_batch, target_audience)\n",
        "    return model.predict(X)\n",
        "\n",
        "\n",
        "prediction_cache = {}\n",
        "\n",
        "def predict_reach(points, target_audience):\n",
        "    # Convert points to a hashable type for caching\n",
        "    points_key = tuple(sorted((p['lon'], p['lat']) for p in points))\n",
        "    # Check if we have a cached result\n",
        "    if points_key in prediction_cache:\n",
        "        return prediction_cache[points_key]\n",
        "\n",
        "    # If not in cache, compute the prediction\n",
        "    df = pd.DataFrame({'points': [points], 'income': [target_audience['income']], 'gender': [target_audience['gender']], 'ageTo': [target_audience['ageTo']], 'ageFrom': [target_audience['ageFrom']] })\n",
        "\n",
        "    df['geometry'] = df['points'].apply(lambda x: Point(float(x[0]['lon']), float(x[0]['lat'])))\n",
        "    gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
        "    gdf.crs = 'EPSG:4326'\n",
        "\n",
        "    # Compute features\n",
        "    red_square = (55.753930, 37.620393)\n",
        "    gdf['distance_to_center'] = gdf.apply(lambda row: geodesic((row.geometry.y, row.geometry.x), red_square).kilometers, axis=1)\n",
        "\n",
        "    coords = np.array([(point.y, point.x) for point in gdf.geometry])\n",
        "    gdf['distance_to_metro'] = metro_tree.query(coords)[0]\n",
        "    gdf['distance_to_shopping_center'] = shopping_tree.query(coords)[0]\n",
        "\n",
        "    possible_matches_index = list(moscow_sindex.intersection(gdf.total_bounds))\n",
        "    possible_matches = moscow.iloc[possible_matches_index]\n",
        "    points_in_districts = gpd.sjoin(gdf, possible_matches, how='left', predicate='within')\n",
        "    gdf['district'] = points_in_districts['name']\n",
        "    gdf['population_density'] = gdf['district'].map(population_density)\n",
        "\n",
        "    # Add target audience data\n",
        "    for key, value in target_audience.items():\n",
        "        gdf[key] = value\n",
        "\n",
        "    # Create dataset for prediction\n",
        "    X = create_dataset(config, gdf)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(X)[0]\n",
        "\n",
        "    # Cache the result\n",
        "    prediction_cache[points_key] = prediction\n",
        "\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "_TEje40l1zGH"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def optimize_campaign_fixed_points(all_points, target_audience, num_points, batch_size=100):\n",
        "    selected_points = []\n",
        "    available_points = all_points.copy()\n",
        "    current_reach = 0\n",
        "\n",
        "    pbar = tqdm(total=num_points, desc=\"Selecting points\")\n",
        "\n",
        "    while len(selected_points) < num_points and available_points:\n",
        "        batch = available_points[:batch_size]\n",
        "        reach_increases = []\n",
        "        for point in batch:\n",
        "            new_reach = predict_reach(selected_points + [point], target_audience)\n",
        "            reach_increase = new_reach - current_reach\n",
        "            reach_increases.append(reach_increase)\n",
        "\n",
        "        best_idx = np.argmax(reach_increases)\n",
        "        best_increase = reach_increases[best_idx]\n",
        "\n",
        "        if best_increase > 0:\n",
        "            best_point = batch[best_idx]\n",
        "            selected_points.append(best_point)\n",
        "            available_points.remove(best_point)\n",
        "            current_reach += best_increase\n",
        "            pbar.update(1)\n",
        "        else:\n",
        "            available_points = available_points[batch_size:]\n",
        "\n",
        "    pbar.close()\n",
        "    return selected_points\n",
        "\n",
        "def chunk_data(data, chunk_size):\n",
        "    for i in range(0, len(data), chunk_size):\n",
        "        yield data[i:i + chunk_size]\n",
        "\n",
        "\n",
        "\n",
        "# def optimize_campaign_variable_points(all_points: list,\n",
        "#                                       target_audience: dict,\n",
        "#                                       min_increase_threshold: float) -> list:\n",
        "#     selected_points = []\n",
        "#     available_points = all_points.copy()\n",
        "\n",
        "#     while True:\n",
        "#         best_point = None\n",
        "#         best_reach_increase = 0\n",
        "\n",
        "#         current_reach = predict_reach(selected_points, target_audience)\n",
        "\n",
        "#         for point in available_points:\n",
        "#             new_reach = predict_reach(selected_points + [point], target_audience)\n",
        "#             reach_increase = new_reach - current_reach\n",
        "\n",
        "#             if reach_increase > best_reach_increase:\n",
        "#                 best_reach_increase = reach_increase\n",
        "#                 best_point = point\n",
        "\n",
        "#         if best_reach_increase > min_increase_threshold:\n",
        "#             selected_points.append(best_point)\n",
        "#             available_points.remove(best_point)\n",
        "#         else:\n",
        "#             break\n",
        "\n",
        "#     return selected_points"
      ],
      "metadata": {
        "id": "zr1yNVz_XSsG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "138edf22-5f2d-419c-e673-a7e2ef3e790e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_points = pd.read_json('unique_points.json')"
      ],
      "metadata": {
        "id": "jgdIB066YlHm"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_audience = {\n",
        "    \"gender\": \"all\",\n",
        "    \"ageFrom\": 25,\n",
        "    \"ageTo\": 45,\n",
        "    \"income\": \"bc\"\n",
        "}\n",
        "all_points = unique_points.to_dict('records')\n"
      ],
      "metadata": {
        "id": "9J-3c3VtaHyF"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_optimization(all_points, target_audience, num_points, batch_size=100):\n",
        "    optimal_points = optimize_campaign_fixed_points(all_points, target_audience, num_points, batch_size)\n",
        "    final_reach = predict_reach(optimal_points, target_audience)\n",
        "    print(f\"Optimal points: {len(optimal_points)}\")\n",
        "    print(f\"Predicted reach: {final_reach}\")\n",
        "    return optimal_points, final_reach"
      ],
      "metadata": {
        "id": "4oDc7yH1aYgb"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_points = run_optimization(all_points, target_audience, num_points=10, batch_size=100)"
      ],
      "metadata": {
        "id": "IaEpoqazanIN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18412f99-fa8c-4eee-abcc-14996ddc71e6"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Selecting points:  10%|█         | 1/10 [02:31<22:43, 151.48s/it]\n",
            "\n",
            "Selecting points:  10%|█         | 1/10 [00:02<00:23,  2.66s/it]\u001b[A\n",
            "Selecting points:  20%|██        | 2/10 [00:20<01:31, 11.40s/it]\u001b[A\n",
            "Selecting points:  30%|███       | 3/10 [00:37<01:39, 14.24s/it]\u001b[A\n",
            "Selecting points:  40%|████      | 4/10 [00:55<01:34, 15.68s/it]\u001b[A\n",
            "Selecting points:  50%|█████     | 5/10 [01:13<01:22, 16.41s/it]\u001b[A\n",
            "Selecting points:  60%|██████    | 6/10 [01:30<01:07, 16.77s/it]\u001b[A\n",
            "Selecting points:  70%|███████   | 7/10 [01:49<00:51, 17.27s/it]\u001b[A\n",
            "Selecting points:  80%|████████  | 8/10 [02:06<00:34, 17.38s/it]\u001b[A\n",
            "Selecting points:  90%|█████████ | 9/10 [02:24<00:17, 17.43s/it]\u001b[A\n",
            "Selecting points: 100%|██████████| 10/10 [02:42<00:00, 16.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal points: 10\n",
            "Predicted reach: 29.009085810755032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "records = pd.read_json('test_data.json')\n",
        "\n",
        "def calculate_new_column(hash_values, points, target_audience):\n",
        "    return [f\"{hash_value},{max(predict_reach(point, target), 0)}\" for hash_value, point, target in zip(hash_values, points, target_audience)]\n",
        "\n",
        "records['hash,value'] = calculate_new_column(records['hash'], records['points'], records['targetAudience'])\n",
        "records.drop(['targetAudience', 'points', 'hash'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "xs3mk70SpVvQ"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "records['hash,value'].to_csv('submission.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHooUkKivr0M",
        "outputId": "7c8615ce-4191-417a-e13c-bf03c6b53dc4"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_model('model.cbm')"
      ],
      "metadata": {
        "id": "FbOuTDSzxP5s"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "13PzBOG0LFtQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}